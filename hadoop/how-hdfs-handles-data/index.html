<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.dfdd3d90caa1e7debe49.css" id="gatsby-global-css">html{font-size:100}body{margin:0;color:#222;line-height:1.625;font-size:1rem;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}body,h1,h2,h3,h4,h5,h6{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1,h2,h3,h4,h5,h6{font-weight:600}h1{font-size:2.5rem;line-height:3.25rem;margin-top:6.5rem;margin-bottom:1.625rem}h2{font-size:1.6875rem;line-height:2.4375rem}h2,h3{margin-top:3.25rem;margin-bottom:.8125rem}h3{font-size:1.375rem;line-height:1.625rem}h4{font-size:1.2rem;margin-top:2.4375rem}h4,h5{line-height:1.625rem;margin-bottom:.8125rem}h5,h6{font-size:1rem;margin-top:4.0625rem}h6{line-height:1.625rem;margin-bottom:.8125rem}img{max-width:100%;margin:inherit auto}hr,img{border:0;display:block}hr{color:#222;height:26px;margin:3.25rem auto;background-size:100% 26px;background-image:linear-gradient(180deg,transparent 1px,transparent 11px,#222 0,#222 15px,transparent 0,transparent 26px);width:6.25rem}a{color:#5d93ff;text-decoration:none}a:active,a:focus,a:hover{color:#f7a046}b,strong{font-weight:600}ul{list-style:square;margin-bottom:1.625rem}ul li{padding:0 .3125rem;margin-bottom:.625rem}p{line-height:1.625rem;margin-bottom:1.625rem}blockquote{padding:0;font-style:italic;text-align:center}figure{display:block;width:100%;height:auto}figcaption{line-height:1.21875rem;margin-top:.40625rem;color:#222;font-size:.875rem;font-style:italic;margin-bottom:0;text-align:center}.anchor{margin-left:-1.875rem!important;padding-right:.875rem!important}@media screen and (min-width:685px){figure.float-left,figure.float-right{max-width:19.375rem;padding:0 1.625rem}.float-right{float:right}.float-left{float:left}}code[class*=language-],pre[class*=language-]{color:#eee;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.7;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-]::selection,code[class*=language-] ::selection,pre[class*=language-]::selection,pre[class*=language-] ::selection{background:#f8c8e2}pre[class*=language-]{padding:1.2em;margin:.5em 0;overflow:auto;border-radius:.3em}:not(pre)>code[class*=language-]{background-color:#f1f3f5;border:1px solid #ced4da;color:#c7254e}pre[class*=language-]{background-color:#282a36}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#6272a4}.token.punctuation{color:#586e75}.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#bd93f9}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string,.token.url{color:#f1fa8c}.token.entity{color:#657b83;background:#eee}.token.atrule,.token.attr-value,.token.keyword{color:#ff79c6}.token.class-name,.token.function{color:#50fa7b}.token.important,.token.regex,.token.variable{color:#cb4b16}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.Author-module--author__photo--36xCH{display:inline-block;margin-bottom:0;border-radius:50%;background-clip:padding-box}.Author-module--author__title--2CaTb{font-size:1.125rem;font-weight:600;line-height:1.82813rem;margin:.8125rem 0}.Author-module--author__title-link--Yrism,.Author-module--author__title-link--Yrism:focus,.Author-module--author__title-link--Yrism:hover{color:#222}.Author-module--author__subtitle--cAaEB{color:#888;line-height:1.625rem;margin-bottom:1.625rem}.Icon-module--icon--Gpyvw{display:inline-block;width:1em;height:1em;stroke-width:0;stroke:currentColor;fill:currentColor;font-style:normal;font-weight:400;speak:none;margin-right:.2em;text-align:center;font-variant:normal;text-transform:none;line-height:1em;margin-left:.2em;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.Contacts-module--contacts--1rGd1{margin-bottom:1.625rem}.Contacts-module--contacts__list--3OgdW{display:flex;flex-flow:row wrap;flex-grow:0;flex-shrink:0;list-style:none;padding:0;margin:.625rem -.1875rem;width:8.75rem}.Contacts-module--contacts__list-item--16p9q{padding:0;margin:.25rem;display:flex;align-content:center;align-items:center;justify-content:center;height:35px;width:2.1875rem;line-height:2.1875rem;border-radius:50%;text-align:center;border:1px solid #ebebeb}.Contacts-module--contacts__list-item-link--2MIDn{border:0;display:flex;color:#222}.Contacts-module--contacts__list-item-link--2MIDn:focus,.Contacts-module--contacts__list-item-link--2MIDn:hover{color:#5d93ff}.Copyright-module--copyright--1ariN{color:#b6b6b6;font-size:.875rem}.Menu-module--menu--Efbin{margin-bottom:1.625rem}.Menu-module--menu__list--31Zeo{list-style:none;padding:0;margin:0}.Menu-module--menu__list-item--1lJ6B{padding:0;margin:.625rem 0}.Menu-module--menu__list-item-link--10Ush{font-size:1rem;color:#222;font-weight:400;border:0}.Menu-module--menu__list-item-link--10Ush:focus,.Menu-module--menu__list-item-link--10Ush:hover{color:#5d93ff;border-bottom:1px solid #5d93ff}.Menu-module--menu__list-item-link--active--2CbUO{color:#222;border-bottom:1px solid #222}.Sidebar-module--sidebar--X4z2p{width:100%}.Sidebar-module--sidebar__inner--Jdc5s{position:relative;padding:1.5625rem 1.25rem 0}@media screen and (min-width:685px){.Sidebar-module--sidebar--X4z2p{width:calc(41.625% - 1.09375rem)}.Sidebar-module--sidebar--X4z2p:nth-child(1n){float:left;margin-right:1.875rem;clear:none}.Sidebar-module--sidebar--X4z2p:last-child{margin-right:0}.Sidebar-module--sidebar--X4z2p:nth-child(12n){margin-right:0;float:right}.Sidebar-module--sidebar--X4z2p:nth-child(12n+1){clear:both}.Sidebar-module--sidebar__inner--Jdc5s{padding:1.875rem 1.25rem 0}.Sidebar-module--sidebar__inner--Jdc5s:after{background:#e6e6e6;background:linear-gradient(180deg,#e6e6e6 0,#e6e6e6 48%,#fff);position:absolute;content:"";width:.0625rem;height:540px;top:30px;right:-10px;bottom:0}}@media screen and (min-width:960px){.Sidebar-module--sidebar--X4z2p{width:calc(33.3% - 1.25rem)}.Sidebar-module--sidebar--X4z2p:nth-child(1n){float:left;margin-right:1.875rem;clear:none}.Sidebar-module--sidebar--X4z2p:last-child{margin-right:0}.Sidebar-module--sidebar--X4z2p:nth-child(3n){margin-right:0;float:right}.Sidebar-module--sidebar--X4z2p:nth-child(3n+1){clear:both}.Sidebar-module--sidebar__inner--Jdc5s{padding:2.5rem}}.Layout-module--layout--3Pyz6{max-width:66.875rem;margin-left:auto;margin-right:auto}.Layout-module--layout--3Pyz6:before{content:"";display:table}.Layout-module--layout--3Pyz6:after{content:"";display:table;clear:both}.Author-module--author--2Yefr{border-top:1px solid #e6e6e6;max-width:60.9375rem;padding-top:1.25rem;line-height:1.625rem;margin-top:1.625rem;margin-bottom:3.25rem}.Author-module--author__bio-twitter--n-O9n{display:block;text-decoration:underline}@media screen and (min-width:685px){.Author-module--author--2Yefr{margin-left:auto;margin-right:auto}}.Content-module--content--3p512{max-width:80rem;padding:0 .9375rem;margin:0 auto}.Content-module--content__title--2BDW9{font-size:2rem;max-width:60.9375rem;font-weight:600;text-align:center;line-height:2.68125rem;margin:1.625rem auto 0}.Content-module--content__body--2TrQ- figure{margin-bottom:1.625rem}.Content-module--content__body--2TrQ- figure blockquote{font-style:italic;text-align:center;margin-top:0;padding:1.625rem 0}.Content-module--content__body--2TrQ- figure blockquote p{max-width:60.9375rem;font-size:1.6817rem;margin-top:0;margin-bottom:1.625rem;line-height:2.4375rem}.Content-module--content__body--2TrQ- a{text-decoration:underline}.Content-module--content__body--2TrQ- *{max-width:60.9375rem;margin-left:auto;margin-right:auto}.Content-module--content__body--2TrQ- img{max-width:100%}@media screen and (min-width:960px){.Content-module--content--3p512{padding:0}.Content-module--content__title--2BDW9{font-size:3rem;line-height:3.65625rem;margin-top:3.65625rem;margin-bottom:2.4375rem}.Content-module--content__body--2TrQ-,.Content-module--content__body--2TrQ- p{font-size:1.125rem;line-height:1.82813rem;margin-bottom:1.82813rem}}.Meta-module--meta__date--29eD7{font-style:italic}.Tags-module--tags--1L_ct{margin-bottom:.8125rem}.Tags-module--tags__list--91FqN{list-style:none;margin:0 -.625rem;padding:0}.Tags-module--tags__list-item--1M30P{display:inline-block;font-size:.8125rem;margin:.125rem}.Tags-module--tags__list-item-link--3SL_8{display:inline-block;height:35px;padding:0 .625rem;line-height:2.1875rem;border:1px solid #e6e6e6;text-decoration:none;border-radius:1.25rem;color:#222}.Tags-module--tags__list-item-link--3SL_8:focus,.Tags-module--tags__list-item-link--3SL_8:hover{color:#5d93ff}.Feed-module--feed__item--2D5rE{margin-bottom:2.03125rem}.Feed-module--feed__item--2D5rE:last-child{margin-bottom:.8125rem}.Feed-module--feed__item-title--3nigr{font-size:1.6875rem;line-height:2.4375rem;margin-top:0;margin-bottom:.8125rem}.Feed-module--feed__item-title-link--iFMRs{color:#222}.Feed-module--feed__item-title-link--iFMRs:focus,.Feed-module--feed__item-title-link--iFMRs:hover{color:#222;border-bottom:1px solid #222}.Feed-module--feed__item-description--1uO8e{font-size:1rem;line-height:1.625rem;margin-bottom:1.21875rem}.Feed-module--feed__item-meta-time--3t1fg{font-size:.875rem;color:#222;font-weight:600;text-transform:uppercase}.Feed-module--feed__item-meta-divider--N-Q0A{margin:0 .3125rem}.Feed-module--feed__item-meta-category-link--23f8F{font-size:.875rem;color:#f7a046;font-weight:600;text-transform:uppercase}.Feed-module--feed__item-meta-category-link--23f8F:focus,.Feed-module--feed__item-meta-category-link--23f8F:hover{color:#5d93ff}.Feed-module--feed__item-readmore--1u6bI{font-size:1rem;color:#5d93ff}.Feed-module--feed__item-readmore--1u6bI:focus,.Feed-module--feed__item-readmore--1u6bI:hover{color:#5d93ff;border-bottom:1px solid #5d93ff}.Page-module--page--2nMky{margin-bottom:3.25rem}.Page-module--page__inner--2M_vz{padding:1.5625rem 1.25rem}.Page-module--page__title--GPD8L{font-size:2.5rem;font-weight:600;line-height:3.25rem;margin-top:0;margin-bottom:2.35625rem}.Page-module--page__body--Ic6i6{font-size:1rem;line-height:1.625rem;margin:0 0 1.625rem}@media screen and (min-width:685px){.Page-module--page--2nMky{width:calc(58.275% - .78125rem)}.Page-module--page--2nMky:nth-child(1n){float:left;margin-right:1.875rem;clear:none}.Page-module--page--2nMky:last-child{margin-right:0}.Page-module--page--2nMky:nth-child(12n){margin-right:0;float:right}.Page-module--page--2nMky:nth-child(12n+1){clear:both}.Page-module--page__inner--2M_vz{padding:1.875rem 1.25rem}}@media screen and (min-width:960px){.Page-module--page--2nMky{width:calc(66.6% - .625rem)}.Page-module--page--2nMky:nth-child(1n){float:left;margin-right:1.875rem;clear:none}.Page-module--page--2nMky:last-child{margin-right:0}.Page-module--page--2nMky:nth-child(3n){margin-right:0;float:right}.Page-module--page--2nMky:nth-child(3n+1){clear:both}.Page-module--page__inner--2M_vz{padding:2.5rem 2.1875rem}}.Pagination-module--pagination--2H3nO{margin-top:3.25rem;display:flex}.Pagination-module--pagination__prev--bet5s{width:50%;text-align:left}.Pagination-module--pagination__prev-link--1Nzs6{color:#f7a046;font-size:1.625rem;font-weight:700}.Pagination-module--pagination__prev-link--1Nzs6:focus,.Pagination-module--pagination__prev-link--1Nzs6:hover{color:#5d93ff}.Pagination-module--pagination__prev-link--disable--Yklx9{pointer-events:none;color:#bbb}.Pagination-module--pagination__next--3hFiN{width:50%;text-align:right}.Pagination-module--pagination__next-link--3FUtA{color:#f7a046;font-size:1.625rem;font-weight:700}.Pagination-module--pagination__next-link--3FUtA:focus,.Pagination-module--pagination__next-link--3FUtA:hover{color:#5d93ff}.Pagination-module--pagination__next-link--disable--30UwZ{pointer-events:none;color:#bbb}.Post-module--post__comments--25y6I,.Post-module--post__footer--3WzWU{max-width:60.9375rem;margin:0 auto;padding:0 .9375rem}.Post-module--post__home-button--16Kl0{display:block;max-width:5.625rem;height:35px;padding:0 1.5rem;line-height:2.1875rem;text-align:center;color:#222;border:1px solid #e6e6e6;border-radius:1.25rem;font-size:1rem;font-weight:400;margin-left:auto;margin-right:auto;margin-top:1.625rem}.Post-module--post__home-button--16Kl0:focus,.Post-module--post__home-button--16Kl0:hover{color:#5d93ff}@media screen and (min-width:960px){.Post-module--post__comments--25y6I,.Post-module--post__footer--3WzWU{padding:0}.Post-module--post__home-button--16Kl0{position:fixed;max-width:auto;margin:0;top:30px;left:30px}}</style><meta name="generator" content="Gatsby 2.32.13"/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>            
              (adsbygoogle = window.adsbygoogle || []).push({
                google_ad_client: "ca-pub-2002611361597206",
                enable_page_level_ads: true
              });
          </script><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-8BHCT1V21F"></script><script>
      
      
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){window.dataLayer && window.dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-8BHCT1V21F', {"send_page_view":false});
      }
      </script><link rel="alternate" type="application/rss+xml" href="/rss.xml"/><style type="text/css">
    .anchor.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .anchor.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .anchor svg,
    h2 .anchor svg,
    h3 .anchor svg,
    h4 .anchor svg,
    h5 .anchor svg,
    h6 .anchor svg {
      visibility: hidden;
    }
    h1:hover .anchor svg,
    h2:hover .anchor svg,
    h3:hover .anchor svg,
    h4:hover .anchor svg,
    h5:hover .anchor svg,
    h6:hover .anchor svg,
    h1 .anchor:focus svg,
    h2 .anchor:focus svg,
    h3 .anchor:focus svg,
    h4 .anchor:focus svg,
    h5 .anchor:focus svg,
    h6 .anchor:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-73379983-2"></script><script>
      
      
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){window.dataLayer && window.dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-73379983-2', {"send_page_view":false});
      }
      </script><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link rel="icon" href="/favicon-32x32.png?v=038375c66d80cd62e2dcfe099e827d4b" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><meta name="theme-color" content="#F7A046"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=038375c66d80cd62e2dcfe099e827d4b"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=038375c66d80cd62e2dcfe099e827d4b"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=038375c66d80cd62e2dcfe099e827d4b"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=038375c66d80cd62e2dcfe099e827d4b"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=038375c66d80cd62e2dcfe099e827d4b"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=038375c66d80cd62e2dcfe099e827d4b"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=038375c66d80cd62e2dcfe099e827d4b"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=038375c66d80cd62e2dcfe099e827d4b"/><title data-react-helmet="true">HDFS가 데이터를 저장하는 방식 - Byeongjin Jason Kang</title><meta data-react-helmet="true" name="description" content="HDFS가 node failure와 data loss에 대비하는 방법"/><meta data-react-helmet="true" property="og:site_name" content="HDFS가 데이터를 저장하는 방식 - Byeongjin Jason Kang"/><meta data-react-helmet="true" name="twitter:card" content="summary"/><meta data-react-helmet="true" name="twitter:title" content="HDFS가 데이터를 저장하는 방식 - Byeongjin Jason Kang"/><link as="script" rel="preload" href="/webpack-runtime-2040cdfedb5607971d09.js"/><link as="script" rel="preload" href="/framework-b049b847da93b37c0f49.js"/><link as="script" rel="preload" href="/532a2f07-e3aef1b806c2b9676cfd.js"/><link as="script" rel="preload" href="/app-98c54d1f8cdf11c156bf.js"/><link as="script" rel="preload" href="/styles-407fe62976dc5310c43e.js"/><link as="script" rel="preload" href="/cd95ea5cbd2c605f26db819f07999610c9ff4310-e4f6eaaafd6673382cfa.js"/><link as="script" rel="preload" href="/643651a62fb35a9bb4f20061cb1f214a352d7976-bf398de8213e62a944ee.js"/><link as="script" rel="preload" href="/component---src-templates-post-template-js-4c210b7b181b96af8152.js"/><link as="fetch" rel="preload" href="/page-data/hadoop/how-hdfs-handles-data/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/251939775.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/401334301.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/583035104.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><script>
void function() {
  window.__onThemeChange = function() {}

  var preferredTheme
  try {
    preferredTheme = localStorage.getItem('theme')
  } catch (err) { }

  function setTheme(newTheme) {
    if (preferredTheme && document.body.classList.contains(preferredTheme)) {
      document.body.classList.replace(preferredTheme, newTheme)
    } else {
      document.body.classList.add(newTheme)
    }

    window.__theme = newTheme
    preferredTheme = newTheme
    window.__onThemeChange(newTheme)
  }

  window.__setPreferredTheme = function(newTheme) {
    setTheme(newTheme)
    try {
      localStorage.setItem('theme', newTheme)
    } catch (err) {}
  }

  var darkQuery = window.matchMedia('(prefers-color-scheme: dark)')
  darkQuery.addListener(function(e) {
    window.__setPreferredTheme(e.matches ? 'dark' : 'light')
  })

  setTheme(preferredTheme || (darkQuery.matches ? 'dark' : 'light'))
}()
    </script><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="Layout-module--layout--3Pyz6"><div><a class="Post-module--post__home-button--16Kl0" href="/">All Articles</a><div><div class="Content-module--content--3p512"><h1 class="Content-module--content__title--2BDW9">HDFS가 데이터를 저장하는 방식</h1><div class="Content-module--content__body--2TrQ-"><p>udemy강의를 들으면서 <a href="https://jasonkang14.github.io/hadoop/hdfs" target="_blank" rel="nofollow noopener noreferrer">HDFS에 대해 한 번 정리한 적</a>이 있다.
이번에는 <a href="https://www.amazon.com/Hadoop-Definitive-Guide-Tom-White/dp/1449311520" target="_blank" rel="nofollow noopener noreferrer">Hadoop - the Defnite Guide</a>를 읽으면서 조금 더 구체적으로 HDFS에 대해 알아보도록 한다. </p>
<h1 id="hdfs의-정의" style="position:relative;"><a href="#hdfs%EC%9D%98-%EC%A0%95%EC%9D%98" aria-label="hdfs의 정의 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>HDFS의 정의</h1>
<p>HDFS는 <code class="language-text">저렴한 하드웨어</code>를 사용해서 <code class="language-text">큰 파일</code>을 <code class="language-text">streaming을 통한 접근</code>이 가능하도록 저장한다. </p>
<p>하나씩 살펴보면. </p>
<ol>
<li>
<p>저렴한 하드웨어 </p>
<ul>
<li>하둡은 고성능의 하드웨어를 필요로 하지 않는다. </li>
<li>저렴한 하드웨어들은 클러스터 안의 node 에서 불량이 발생할 가능성이 높다.</li>
<li>하둡은 이러한 불량이 발생했을 때 사용자들이 불편함을 느끼지 못하도록 설계되어 있다. </li>
</ul>
</li>
</ol>
<p>저렴한 하드웨어가 정확히 뭔지 찾아보았다 </p>
<p><img src="https://i.imgur.com/jIHi2bN.png" alt="hardware-spec"> </p>
<p>출처: <a href="https://docs.informatica.com/data-engineering/data-engineering-integration/h2l/1415-tuning-and-sizing-guidelines-for-data-engineering-integrati/tuning-and-sizing-guidelines-for-data-engineering-integration--1/sizing-recommendations/hadoop-cluster-hardware-recommendations.html" target="_blank" rel="nofollow noopener noreferrer">Hadoop Cluster Hardware Recommendation</a>       </p>
<p>공식문서에 따르면 <a href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html#The+Persistence+of+File+System+Metadata" target="_blank" rel="nofollow noopener noreferrer">RAM 4GB도 충분하도록 설계되었다</a>고 한다     </p>
<ol start="2">
<li>
<p>큰 파일</p>
<ul>
<li>테라바이트, 심지어 페타바이트 크기의 파일들도 저장함</li>
</ul>
</li>
<li>
<p>streaming을 통한 접근</p>
<ul>
<li>HDFS는 한번 write하고 여러번 read하는 패턴을 따른다. </li>
<li>일반적으로 데이터는 한 번 write하면 다양한 사람들이 read해서 분석하기 때문이다. </li>
<li>데이터 분석은 모든 node를 필요로 하기 때문에, 첫번째 node를 얼마나 빨리 읽어내느냐보다 모든 데이터들을 얼마나 빨리 읽어내느냐가 중요하다. </li>
</ul>
</li>
</ol>
<h3 id="ins따라서-아래와-같은-상황에서는-hdfs가-적합하지-않을-수-있다ins" style="position:relative;"><a href="#ins%EB%94%B0%EB%9D%BC%EC%84%9C-%EC%95%84%EB%9E%98%EC%99%80-%EA%B0%99%EC%9D%80-%EC%83%81%ED%99%A9%EC%97%90%EC%84%9C%EB%8A%94-hdfs%EA%B0%80-%EC%A0%81%ED%95%A9%ED%95%98%EC%A7%80-%EC%95%8A%EC%9D%84-%EC%88%98-%EC%9E%88%EB%8B%A4ins" aria-label="ins따라서 아래와 같은 상황에서는 hdfs가 적합하지 않을 수 있다ins permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><ins>따라서 아래와 같은 상황에서는 HDFS가 적합하지 않을 수 있다.</ins></h3>
<ol>
<li>데이터를 읽어들이는데 10ms정도 소요되는 경우 (매우 짧다는 뜻)</li>
<li>
<p>작은 크기의 파일 여러개를 읽어들이는 경우</p>
<ul>
<li>HDFS의 namenode가 데이터가 datanode들에 어떻게 저장되어 있는지에 대한 metadata를 메모리에 저장해서 가지고 있는데, 파일이 여러개면 메모리가 엄청 커야하는 문제가 있음</li>
</ul>
</li>
<li>write가 빈번한 경우</li>
</ol>
<h1 id="hdfs-concepts" style="position:relative;"><a href="#hdfs-concepts" aria-label="hdfs concepts permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>HDFS Concepts</h1>
<h3 id="blocks" style="position:relative;"><a href="#blocks" aria-label="blocks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Blocks</h3>
<p>HDFS는 데이터를 <code class="language-text">128MB 사이즈의 block</code> 단위로 저장한다. 저장되는 파일의 크기가 128MB보다 작은 경우에는 디스크에서 128MB를 모두 차지하지 않는다.</p>
<p>일반적으로 disk 에서 block의 크기는 512bytes 수준이기 때문에 128MB가 너무 크다고 생각할 수도 있다. HDFS는 데이터를 찾는 시간을 줄이기 위해 큰 block 사이즈를 선택했다. </p>
<p>책에 나와있지는 않지만 하둡의 등장 배경이 read가 오래 걸리기 때문에 분산저장을 한다고 했는데, 어차피 read하는 속도는 100MB/s 수준이니까, 분산저장되는 node의 숫자를 줄여서 빠르게 찾아내서 전송하는 것을 택한 것 같다.
128MB는 default이고, 더 크게 설정하는 경우도 많다고 한다.</p>
<p>Block Abstraction이 가져오는 장점은 여러가지가 있는데</p>
<ol>
<li>
<p>파일이 디스크보다 커도 된다는 것</p>
<ul>
<li>하나의 파일의 block들이 같은 클러스터에 저장될 필요가 없기 때문에 어떠한 용량의 파일도 저장이 가능함</li>
</ul>
</li>
<li>
<p>Abstraction을 파일 단위가 아니라 block단위로 하면서 시스템이 더 간단해 진다는 것</p>
<ul>
<li>block은 용량이 고정되어 있기 때문에 디스크에 몇 개의 block이 저장될 수 있는지 계산하기 쉽고</li>
<li>permission과 같은 파일의 기타 metadata는 block과 같이 저장될 필요가 없기 때문</li>
<li>다른 metadata는 다른데서 관리함 -> 파일 저장이 쉬워진다는 뜻인 것 같음</li>
</ul>
</li>
<li>
<p>replication에 유리하다는 것 </p>
<ul>
<li>block이 corrupt되는 것과 각종 에러에 대비하기 위해 block은 일반적으로 3개씩 replicate되어 저장됨</li>
<li>특정 block에 접근할 수 없게 되면, replicate된 다른 block에 접근할 수 있음 </li>
<li><strong>사용자는 이 사실을 모름</strong> &#x3C;&#x3C;&#x3C;&#x3C;&#x3C; 이 말을 정말 자주함</li>
</ul>
</li>
</ol>
<h3 id="namenodes-and-datanodes" style="position:relative;"><a href="#namenodes-and-datanodes" aria-label="namenodes and datanodes permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Namenodes and Datanodes</h3>
<p>HDFS는 master 역할을 하는 <code class="language-text">namenode</code>와 worker 역할을 하는 <code class="language-text">datanode</code>로 이루어져 있음</p>
<p><code class="language-text">namenode</code>는 <code class="language-text">namespace image</code>와 <code class="language-text">edit log</code>의 형태로 filesystem tree와 각 파일들의 metadata를 저장한다. 그리고 특정 파일의 block들이 어떤 <code class="language-text">datanode</code>에 저장되어 있는지에 대한 정보도 가지고 있다. 하지만 <code class="language-text">datanode</code>의 정보는 memory에서 관리한다. HDFS가 재가동되면, <code class="language-text">namenode</code>는 <code class="language-text">edit log</code>를 기반으로 만들어진 <code class="language-text">namespace image</code>에서 block들의 정보를 가져오고, 빠지는 정보들만 <code class="language-text">datanode</code>와 소통해서 다시 채운다. <code class="language-text">edit log</code>는 <code class="language-text">namespace image</code>가 업데이트 될 때마다 버려진다 </p>
<p><code class="language-text">datanode</code>는 block들을 저장하고, 요청이 들어오면 그 block들을 client에 전달한다. 그리고 주기적으로 <code class="language-text">namenode</code>에 자신들이 저장하고 있는 block 정보들을 전달한다.</p>
<p><code class="language-text">namenode</code>가 HDFS내에 파일이 어떻게 저장되어있는지에 대한 정보를 가지고 있기 때문에, <code class="language-text">namenode</code>가 날아가면 시스템을 다시 구축할 수 없다. 그래서 하둡은 <code class="language-text">namenode</code>가 내려가는 것에 대비해서 두가지 방식을 구현한다.(뒤에 나오는 HA까지 하면 사실 3가지)</p>
<ol>
<li>
<p>secondary namenode</p>
<ul>
<li>
<p>주기적으로 <code class="language-text">edit log</code>가 너무 커지기 전에 <code class="language-text">namespace image</code>를 merge함</p>
<ul>
<li>도커에서 이미지 커밋하는거랑 비슷한 것 같음</li>
</ul>
</li>
<li><code class="language-text">namespace image</code>를 merge하는데 CPU를 많이 사용하기 때문에 일반적으로 primary namenode와 다른 기기에서 구동됨</li>
<li>주기적으로 merge가 이루어지기 때문에 primary node와 완전히 똑같지는 않음 </li>
<li>따라서 primary node가 완전히 죽으면 data loss는 불가피함 </li>
<li>primary node가 죽으면 NFS에 백업된 metadata를 사용해서 secondary node를 primary로 전환해서 구동하는 것이 일반적임</li>
</ul>
</li>
<li>
<p>filesystem metadata를 백업하는 것 </p>
<ul>
<li><code class="language-text">namenode</code>는 persistent state(<code class="language-text">edit log</code>)를 local disk나 remote NFS에 저장할 수 있다. </li>
<li>secondary namenode와 다르게, 죽으면 백업된 metadata를 사용해서 기존의 primary를 다시 올린다는 것 같다</li>
</ul>
</li>
</ol>
<h3 id="block-caching" style="position:relative;"><a href="#block-caching" aria-label="block caching permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Block Caching</h3>
<p>일반적으로 <code class="language-text">datanode</code>는 disk에서 block을 읽어오는데, 자주 접근하는 block들은 <code class="language-text">off-heap block cache</code>에 저장할 수 있다. default는 하나의 <code class="language-text">block</code>을 하나의 <code class="language-text">datanode</code>의 메모리에 cache하는 것이다(파일마다 설정을 다르게 할 수는 있음). <code class="language-text">MapReduce</code>나 <code class="language-text">Spark</code> JobScheduler들은 cache를 활용해서 빠른 read를 통해 효율을 높일 수 있다. cache를 원하는 클라이언트는 <code class="language-text">cache directive</code>를 <code class="language-text">cache pool</code>에 추가해서 어떤 파일을 얼마나 오랫동안 <code class="language-text">cache</code>할지 지정할 수 있다. </p>
<p><img src="https://i.imgur.com/DgUmbuy.png" alt="how-hdfs-cache-works"></p>
<p><code class="language-text">cache directive</code>는 cache에 저장하고자 하는 경로이다. cache는 재귀형식이 아니라서 해당 경로에 있는 파일들만 cache된다. 하위 디렉토리의 파일들은 cache에 저장되지 않는다 <code class="language-text">cache pool</code>은 <code class="language-text">cache directive</code>와 permission을 모아둔 그룹정도로 이해하면 된다. <code class="language-text">cache pool</code>은 resource 관리도 가능한데, pool에 모인 directive들의 최대 용량을 제한할 수 있다. HDFS 내에 따로 cache를 위해 따로 배정된 메모리가 있는데, 디폴트는 최대로 다 쓰는건데, 설정해서 줄일 수 있다.</p>
<h3 id="hdfs-federation" style="position:relative;"><a href="#hdfs-federation" aria-label="hdfs federation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>HDFS Federation</h3>
<p><code class="language-text">namenode</code>가 파일시스템에 대한 metadata를 메모리에 저장하기 때문에, 엄청 많은 파일들을 저장하는 클러스터의 경우에는 memory 크기 때문에 scalability가 떨어질 수 있다. 그래서 하둡 2.X대 버전부터 HDFS Federation이라는 컨셉을 도입했는데, 클러스터가 namenode를 추가해서 scaling할 수 있도록 하는 방식이다. 예를들면 namenode 1은 /user에 저장된 파일들의 metadata를 관리하고 namenode 2는 /share에 저장된 파일들의 metadata를 관리하는 식.</p>
<p>그렇다면 사용자가 HDFS에 접근할 때 어떤 namenode를 통해 데이터를 불러와야 하는지에 대한 정보를 어딘가 또 저장해야하는데, 이거는 client에서 file-path와 <code class="language-text">namenode</code>를 mapping한 테이블을 저장해서 가지고있다.</p>
<h3 id="hdfs-high-availability" style="position:relative;"><a href="#hdfs-high-availability" aria-label="hdfs high availability permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>HDFS High Availability</h3>
<p><code class="language-text">namenode</code> 하나를 active standby로 두고, primary로 구동되는 것이 죽으면 바로 교체하는 방식. secondary namenode를 사용할 경우 다시 올라갈 때까지 데이터 write가 불가하다던지 하는 문제가 있는데 이를 해결한다. active standby는 primary와 storage와 <code class="language-text">edit log</code>를 같이 사용한다. 따라서 primary가 죽어서 active standby가 구동될 때, 이 <code class="language-text">edit log</code>를 활용해서 기존에 돌고있던 primary와 같은 configuration을 가지고 돌아가게 된다. </p>
<p>위에서 언급한 <code class="language-text">storage</code>는 두가지 옵션이 있다. </p>
<ol>
<li>NFS filer</li>
<li>
<p>Quorum Journal Manager(QJM)</p>
<ul>
<li>QJM은 HDFS 구현을 위해 존재한다. </li>
<li>목적 자체가 highly available edit log를 active standby에 제공하기 위한 것이다. </li>
<li>그래서 이걸 추천한다</li>
<li>QJM은 <code class="language-text">journal node</code>들로 이루어져 있는데, <code class="language-text">ediit log</code>를 이 <code class="language-text">journal node</code>들에 저장한다. </li>
<li>ZooKeeper와 유사하게 3개의 <code class="language-text">journal node</code>들이 있다.</li>
</ul>
</li>
</ol>
<p><code class="language-text">namenode</code>가 metadata를 disk가 아니라 memory에 저장하기 때문에, datanode는 primary namenode와 active standby 모두에게 block의 위치를 전달해야 한다. active standby도 metadata를 메모리에 저장하고 있기 때문에, 구동하는데 걸리는 시간이 매우 짧다는 이점이 있다. </p>
<p>하지만 실제로는 조금 오래 걸리는 것처럼 느껴질 수 있는데, 이는 시스템이 <code class="language-text">정말로 primary namenode가 내려갔는지</code>를 판단하는데 오래 걸리기 때문이다. 예를 들면 네트워크 문제로 파일을 못 불러오는 것인데, primary namenode가 내려갔다고 판단해서 active standby를 구동하는 것은 낭비가 될 수 있다. </p>
<p>primary가 내려갔는지 판단해서 secondary를 구동시키는 시스템을 <code class="language-text">failover system</code>이라고 한다. 그리고 <code class="language-text">ZooKeeper</code>같은 것을 사용해서 하나의 namenode만 올라간게 맞는지 확인하고, secondary나 standby가 올라가는 준비중일때, 기존에 구동되고있던 primary namenode가 시스템을 corrupt하는 것을 방지하는 것을 <code class="language-text">fencing</code>이라고 한다. QJM은 한번에 하나의 <code class="language-text">namenode</code>만 <code class="language-text">edit log</code>를 작성할 수 있도록 하는데, 기존 active namenode가 클라이언트의 read request를 수용할 수도 있다. 따라서 SSH fencing등의 코드를 작성해서 방지하는 것이 중요하다. </p>
<p>NFS filer는 QJM과 달리 한 번에 하나의 <code class="language-text">namenode</code>만 <code class="language-text">edit log</code>를 업데이트 할 수 있는 설정이 없기 때문에 fencing은 더 빡세게 작성해야 한다. <code class="language-text">fencing</code>에는 다양한 방법들이 있는데, <code class="language-text">namenode</code>가 NFS에 접근할 수 있는 권한을 제거하거나, 네트워크 설정을 통해 해당 port로의 접근을 제한하는 것들을 포함한다. 최악의 경우에는 기존 namenode의 전원을 꺼버릴 수도 있다. </p>
<p>client-side도 에러가 발생할 수 있는데, 이건 library를 사용해서 처리한다.</p>
<h1 id="the-command-line-interface" style="position:relative;"><a href="#the-command-line-interface" aria-label="the command line interface permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Command-Line Interface</h1>
<p>하둡은 개발자들이 좋아하는 CLI를 제공한다. 아래 예제는 HDFS를 하나의 machine에서 구동한다는 전제를 가지고 한다. </p>
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token comment"># configuration</span>

fs.defaultFS <span class="token operator">=</span> hdfs://loaclhost/
dfs.replication <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment"># default는 3인데 예제가 기계 하나에서 돌기때문에 replication을 방지함</span></code></pre></div>
<p>로컬에서 하둡으로 파일 옮기기 <code class="language-text">hdfs://localhost</code>는 생략해도 된다</p>
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">hadoop fs -copyFromLocal input/docs/quangle.txt hdfs://localhost/user/tom/quangle.txt
hadoop fs -copyFromLocal input/docs/quangle.txt /user/tom/quangle.txt
hadoop fs -copyFromLocal input/docs/quangle.txt quangle.txt</code></pre></div>
<p>하둡에서 로컬로 옮기기</p>
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">hadoop fs -copyToLocal quangle.txt quangle.copy.txt</code></pre></div>
<p>하둡에 디렉토리 생성</p>
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">hadoop fs -mkdir books
hadoop fs -ls <span class="token builtin class-name">.</span></code></pre></div>
<p><img src="https://i.imgur.com/2I1mdWw.png" alt="hadoop-fs-ls">
<br /></p>
<p>파일 정보를 리눅스랑 유사하게 읽어올 수 있고, 사용자와 권한 사이에 숫자는 replication 숫자를 나타낸다.
하둡에서 파일 권한은 리눅스랑 유사하게 read(r), write(wr) execute(x)로 구성된다. read, write는 말 그대로이고, execute는 무시되는데, HDFS 안에서 파일을 실행하는 것이 불가능하기 때문이다.
각각의 파일과 디렉토리는 <code class="language-text">owner</code>, <code class="language-text">group</code>, <code class="language-text">mode</code>가 있다. <code class="language-text">mode</code>는 <code class="language-text">owner</code>의 권한이고, <code class="language-text">owner</code>는 <code class="language-text">group</code>에 속해있다. </p>
<h1 id="hadoop-filesystems" style="position:relative;"><a href="#hadoop-filesystems" aria-label="hadoop filesystems permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Hadoop Filesystems</h1>
<p>파일시스템 종류는 다양하다. HDFS를 꼭 사용할 필요는 없다.
<img src="https://i.imgur.com/2I1mdWw.png" alt="hadoop-filesystem-table">
이거 이외에 Azure와 <a href="https://www.openstack.org/" target="_blank" rel="nofollow noopener noreferrer">OpenStack</a> Swift도 존재한다 - Swift == Openstack equivalent of AWS S3 </p>
<h3 id="interfaces" style="position:relative;"><a href="#interfaces" aria-label="interfaces permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Interfaces</h3>
<p>하둡은 Java로 구현됐기 때문에, 상당수의 interaction이 Java API를 통해 이루어진다. Java API이외에 하둡과 소통할 수 있는 다른 방법들을 소개한다. </p>
<h4 id="http" style="position:relative;"><a href="#http" aria-label="http permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>HTTP</h4>
<p><code class="language-text">WebHDFS</code> protocol이 제공하는 HTTP REST API를 사용해서 하둡에 접근할 수 있다. HTTP Client는 native Java Client보다 느리기 때문에 큰 용량의 데이터를 transfer할 때는 가급적 사용하지 않는 편이 좋다. HTTP를 사용해서 hadoop에 접근할 수 있는 방법은 두가지가 있는데, </p>
<ol>
<li>HDFS daemon이 HTTP request를 직접 처리하는 것과</li>
<li><code class="language-text">DistributedFileSystem API</code>를 사용해서 proxy를 통해 접근하는 방법이 있다. </li>
</ol>
<p><img src="https://i.imgur.com/0LZICwc.png" alt="how-to-access-haddop-via-http"></p>
<h4 id="c" style="position:relative;"><a href="#c" aria-label="c permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>C</h4>
<p><code class="language-text">libhdfs</code>라는 C library를 사용해서 하둡에 접근할 수 있다. <code class="language-text">libhdfs</code> 라이브러리는 Java의 <code class="language-text">FileSystem</code> interface와 매우 유사하다.</p>
<h4 id="nfsnetwork-filesystem" style="position:relative;"><a href="#nfsnetwork-filesystem" aria-label="nfsnetwork filesystem permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>NFS(Network FileSystem)</h4>
<p>HDFS를 로컬 클라이언트의 filesystem에 NFSv3 gateway를 사용해서 mount시킬 수 있다. read와 write가 가능하다. append를 통한 파일 수정은 가능한데, HDFS가 파일의 끝에만 write만 가능하도록 디자인 되어있기 때문에 랜덤으로 수정하는 것은 불가능하다. </p>
<h4 id="fuse" style="position:relative;"><a href="#fuse" aria-label="fuse permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>FUSE</h4>
<p>Filesystem in Userspace의 약자. Unix filesystem처럼 user space에 구현된 filesystem이다. (kernerl에 파일을 write할 수 있는 기능??) HDFS를 local filesystem처럼 mount시킬 수 있는 방법이다. NFS가 FUSE보다 안정적이기 때문에 가능하면 안쓰는걸 추천한다.</p>
<h1 id="java-예제" style="position:relative;"><a href="#java-%EC%98%88%EC%A0%9C" aria-label="java 예제 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Java 예제</h1>
<p>DataFlow에 예제 코드로 추가했다</p>
<h1 id="data-flow" style="position:relative;"><a href="#data-flow" aria-label="data flow permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data Flow</h1>
<h3 id="file-read" style="position:relative;"><a href="#file-read" aria-label="file read permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>File Read</h3>
<p><img src="https://i.imgur.com/Ii0s5lg.png" alt="how-to-read-from-hdfs"></p>
<ol>
<li><code class="language-text">FileSytem</code> object에서 <code class="language-text">.open()</code>을 호출한다</li>
</ol>
<div class="gatsby-highlight" data-language="java"><pre class="language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FileSystemCat</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
        <span class="token class-name">String</span> uri <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
        <span class="token class-name">Configuration</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">FileSystem</span> fs <span class="token operator">=</span> <span class="token class-name">FileSystem</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>URI<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>uri<span class="token punctuation">)</span><span class="token punctuation">,</span> conf<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 이 파일시스템을 사용해서</span>
        <span class="token class-name">InputStream</span> in <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
        <span class="token keyword">try</span> <span class="token punctuation">{</span>
            in <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token keyword">open</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>uri<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 여기 호출! FSDataInputStream을 return함</span>
            <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>in<span class="token punctuation">,</span> <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// IOUtils는 하둡에서 제공</span>
            <span class="token comment">// 4096은 buffer size이고 </span>
            <span class="token comment">// true/false는 데이터 read가 끝나면 연결을 끊을지/말지 결정하는 것</span>
        <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>
            <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>in<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span></code></pre></div>
<ol start="2">
<li>
<p><code class="language-text">DistributedFileSystem</code>이 <code class="language-text">namenode</code>에 접근해서 요청하는 파일의 block 위치를 읽어온다</p>
<ul>
<li><code class="language-text">namenode</code>는 처음 block들이 어떤 <code class="language-text">datanode</code>에 저장되어 있는지 <code class="language-text">client</code>와 가까운 순서대로 sorting해서 정보를 제공한다.</li>
<li><code class="language-text">MapReduce</code>등의 케이스로 client가 datanode라면 client는 local datanode에서 데이터를 read한다. </li>
<li><code class="language-text">DistributedFileSystem</code>은 <code class="language-text">FSDataInputStream</code>을 return한다</li>
</ul>
</li>
<li><code class="language-text">client</code>가 <code class="language-text">FSDataInputStream</code>에 <code class="language-text">.read()</code> 호출</li>
</ol>
<div class="gatsby-highlight" data-language="java"><pre class="language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FSDataInputStream</span> <span class="token keyword">extends</span> <span class="token class-name">DataInputStream</span>
    <span class="token keyword">implements</span> <span class="token class-name">Seekable</span><span class="token punctuation">,</span> <span class="token class-name">PositionedReadable</span> <span class="token punctuation">{</span>
<span class="token punctuation">}</span>

<span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">Seekable</span> <span class="token punctuation">{</span>
    <span class="token keyword">void</span> <span class="token function">seek</span><span class="token punctuation">(</span><span class="token keyword">long</span> pos<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">;</span>
    <span class="token keyword">long</span> <span class="token function">getPos</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">PositionedReadable</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">read</span><span class="token punctuation">(</span><span class="token keyword">long</span> position<span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> buffer<span class="token punctuation">,</span> <span class="token keyword">int</span> offset<span class="token punctuation">,</span> <span class="token keyword">int</span> length<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">;</span>

    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFully</span><span class="token punctuation">(</span><span class="token keyword">long</span> position<span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> buffer<span class="token punctuation">,</span> <span class="token keyword">int</span> offset<span class="token punctuation">,</span> <span class="token keyword">int</span> length<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">;</span>

    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFully</span><span class="token punctuation">(</span><span class="token keyword">long</span> position<span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> buffer<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span></code></pre></div>
<p><code class="language-text">read()</code>를 호출하면, position에서부터 데이터를 read하기 시작함. 읽어드린 bytes를 <code class="language-text">int</code>로 리턴한다. <code class="language-text">readFully()</code>호출하면 다 read함
<code class="language-text">DFSInputStream</code>이 가지고 있는 client로부터 가장 가까운 datanode의 주소를 사용해서 <code class="language-text">client</code>는 <code class="language-text">datanode</code>와 연결한다.</p>
<ol start="4">
<li><code class="language-text">DFSInputStream</code>이 <code class="language-text">datanode</code>에 <code class="language-text">.read()</code>호출해서 데이터를 read함. </li>
<li>
<p><code class="language-text">block</code>의 끝에 도달하면, <code class="language-text">DFSInputStream</code>은 connection을 닫고, 다음 <code class="language-text">block</code>을 읽어들일 <code class="language-text">datanode</code>를 찾는다. </p>
<ul>
<li>이 과정은 client에게 안내되지 않는다(예를들면 3번 데이터노드에서 데이터를 읽기 시작합니다 등의 메세지 없음)</li>
<li><code class="language-text">block</code>들은 순서대로 읽어진다</li>
<li><code class="language-text">DFSInputStream</code>이 <code class="language-text">datanode</code>로 연결하고, 이후에 <code class="language-text">block</code>을 더 read해야하면 <code class="language-text">namenode</code>와 소통해서 다음 <code class="language-text">datanode</code>의 위치를 받아온다. </li>
<li><code class="language-text">datanode</code>로부터 데이터를 읽어올 때 에러가 발생하면 가장 가까운 <code class="language-text">datanode</code>로부터 데이터에서 데이터를 읽으려고 시도한다.</li>
<li>또한 실패한 <code class="language-text">datanode</code>를 기억해서, 해당 <code class="language-text">datanode</code>로는 다시 read request를 보내지 않는다. </li>
<li>문제가 있는 <code class="language-text">block</code>은 <code class="language-text">namenode</code>에게 알려준다</li>
</ul>
</li>
</ol>
<p><img src="https://i.imgur.com/xcIUF0l.png" alt="distance-between-datanodes"></p>
<ol start="6">
<li>
<p>read가 끝나면 <code class="language-text">FSDataInputStream</code>에 <code class="language-text">.close()</code>호출</p>
<ul>
<li><code class="language-text">IOUtils</code>는 하둡에서 제공</li>
<li><a href="https://hadoop.apache.org/docs/r2.6.3/api/org/apache/hadoop/io/IOUtils.html" target="_blank" rel="nofollow noopener noreferrer">API 문서</a>가 나름 친절한편</li>
</ul>
</li>
</ol>
<p>HDFS에서는 클라이언트가 <code class="language-text">namenode</code>가 제공하는 정보를 바탕으로 <code class="language-text">datanode</code>에 직접적으로 연결한다. 따라서 traffic이 각각의 datanode로 분산되기 때문에 여러 사용자들이 동시에 접근해도 문제없이 요청을 처리할 수 있다는 장점이 있다. </p>
<h3 id="file-write" style="position:relative;"><a href="#file-write" aria-label="file write permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>File Write</h3>
<p><img src="https://i.imgur.com/02uyjyh.png" alt="hdfs-write"></p>
<ol>
<li>
<p><code class="language-text">DistributedFileSystem</code>에 <code class="language-text">.create()</code>호출</p>
<div class="gatsby-highlight" data-language="java"><pre class="language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FileCopyWithProgress</span> <span class="token punctuation">{</span>
<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
<span class="token class-name">String</span> localSrc <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token class-name">String</span> dst <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>

<span class="token class-name">InputStream</span> in <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BufferedInputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span>localSrc<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">Configuration</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">FileSystem</span> fs <span class="token operator">=</span> <span class="token class-name">FileSystem</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>URI<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>dst<span class="token punctuation">)</span><span class="token punctuation">,</span> conf<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">OutputStream</span> out <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>dst<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Progressable</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 여기 호출</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">progress</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"."</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>in<span class="token punctuation">,</span> out<span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span></code></pre></div>
</li>
<li>
<p><code class="language-text">DistributedFileSystem</code>이 <code class="language-text">namenode</code>와 소통해서 새로운 파일을 생성하려고 함. </p>
<ul>
<li><code class="language-text">namenode</code>는 client가 생성하고자 하는 파일이 존재 하지 않는 것을 확인하고,</li>
<li>client가 write permission이 있는지 확인하고, </li>
<li>새로운 파일이 생성된다는 것을 기록한다. </li>
<li>어떤 <code class="language-text">datanode</code>에 write를 시작할지도 정보를 전달함</li>
</ul>
</li>
<li>
<p>client가 write를 시작한다</p>
<ul>
<li><code class="language-text">DFSOutputStream</code>이 파일을 packet으로 나눔</li>
<li>internal queue인 <code class="language-text">data queue</code>와 <code class="language-text">ack queue</code>에 저장한다. </li>
</ul>
</li>
<li>
<p><code class="language-text">DataStreamer</code>는 <code class="language-text">namenode</code>로 부터 데이터를 저장할 <code class="language-text">datanode</code>를 받아와서 <code class="language-text">data queue</code>에서 packet을 꺼내서 <code class="language-text">datanode</code>에 전달한다</p>
<ul>
<li>replication level에 따라 <code class="language-text">datanode</code>는 packet을 write한 후에 relaction할 다음 <code class="language-text">datanode</code>들로 packet을 전달한다.</li>
</ul>
</li>
<li>
<p><code class="language-text">DFSOutputStream</code>은 <code class="language-text">ack queue</code>를 활용해서 <code class="language-text">data queue</code>에서 나간 packet들이 <code class="language-text">datanode</code>에 제대로 write됐는지 관리한다</p>
<ul>
<li>모든 <code class="language-text">datanode</code>들에 packet이 write된 것을 확인하면 <code class="language-text">ack queue</code>에서 해당 packet을 제거한다.(replication 확인)</li>
<li>
<p><code class="language-text">datanode</code>가 패킷을 제대로 write하지 못한 경우 아래와 같이 해결한다</p>
<ul>
<li>write pipeline이 닫힌다</li>
<li><code class="language-text">datanode</code>들이 남김없이 packet을 write하기 위해 <code class="language-text">ack queue</code>에 남아있는 패킷들은 <code class="language-text">data queue</code>의 앞으로 옮겨진다.</li>
<li>write에 실패한 <code class="language-text">datanode</code>의 <code class="language-text">block</code>들은 제거된다. </li>
<li>정상적으로 작동하는 <code class="language-text">datanode</code>는 <code class="language-text">block</code>의 상태를 <code class="language-text">namenode</code>에 전달하고, 이 <code class="language-text">datanode</code>를 기반으로 새로운 pipeline이 작동하기 시작한다. </li>
<li>replication이 replication level만큼 이루어지지 않은 경우 추가 replication을 진행한다. </li>
</ul>
</li>
</ul>
</li>
<li>
<p>write가 끝나면 client는 <code class="language-text">.close()</code>를 호출한다.</p>
<ul>
<li>datanode pipeline에 packet이 남아있다면 flush하고</li>
<li><code class="language-text">DFSOutputStream</code>으로부터 <code class="language-text">ack</code> signal을 기다린다.</li>
</ul>
</li>
<li><code class="language-text">namenode</code>에 write가 끝났다고 전달한다.
</li>
</ol>
<h3 id="replication" style="position:relative;"><a href="#replication" aria-label="replication permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Replication</h3>
<p><code class="language-text">namenode</code>는 replication을 저장할 <code class="language-text">datanode</code>를 선택할 때 write bandwidth와 read bandwidth를 고려한다. 모든 replica들을 하나의 <code class="language-text">datanode</code>에 저장하면 write bandwidth에 유리하지만, 데이터가 정상적으로 relicate되었다고 볼 수 없다. 그렇다고 replica를 아예 다른 데이터 센터에 저장하면 relication은 완전하겠지만 write bandwidt측면에서 불리하다. </p>
<p>하둡은 일반적으로 첫번째 relica를 client와 같은 node에 저장한다. client가 cluster밖에서 돌고있으면 랜덤으로 node를 선택한다. 두번째 replica는 다른 rack에 저장되고, 세번째 replica는 두번째 replica와 같은 rack의 다른 node에 저장된다. </p>
<h3 id="coherency-model" style="position:relative;"><a href="#coherency-model" aria-label="coherency model permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Coherency Model</h3>
<p>coherency는 read와 write를 쉽게하기 위해 고안되었다.
file을 write했다면 파일을 읽어드릴 수 있어야한다.</p>
<div class="gatsby-highlight" data-language="java"><pre class="language-java"><code class="language-java"><span class="token class-name">Path</span> p <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"p"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">assertThat</span><span class="token punctuation">(</span>fs<span class="token punctuation">.</span><span class="token function">exists</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">is</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>
<p>그런데 write된 파일을 읽어드릴 수 없는 경우에는 length가 0로 나타난다</p>
<div class="gatsby-highlight" data-language="java"><pre class="language-java"><code class="language-java"><span class="token class-name">Path</span> p <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"p"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">OutputStream</span> out <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">;</span>
out<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token string">"content"</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token string">"UTF-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
out<span class="token punctuation">.</span><span class="token function">flush</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">assertThat</span><span class="token punctuation">(</span>fs<span class="token punctuation">.</span><span class="token function">getFileStatus</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getLen</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">is</span><span class="token punctuation">(</span><span class="token number">0L</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>
<p>적어도 하나의 block이 write되어야 첫번째 block이 read가능하다. 다양한 사용자가 동시에 접근한다고 할 때 같은 값을 read하는 것을 보장하기 위한 것으로 보인다.
HDFS는 모든 buffer들을 flush하기 위해 <code class="language-text">hflush()</code> method를 제공한다. <code class="language-text">hflush()</code>가 성공했다고 return하면, 모든 <code class="language-text">datanode</code>들에 파일이 정상적으로 write됐다는 것을 의미한다. </p>
<div class="gatsby-highlight" data-language="java"><pre class="language-java"><code class="language-java"><span class="token class-name">Path</span> p <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"p"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">FSDataOutputStream</span> out <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">;</span>
out<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token string">"content"</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token string">"UTF-8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
out<span class="token punctuation">.</span><span class="token function">hflush</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">assertThat</span><span class="token punctuation">(</span>fs<span class="token punctuation">.</span><span class="token function">getFileStatus</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getLen</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">is</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">long</span><span class="token punctuation">)</span> <span class="token string">"content"</span><span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>
<p><code class="language-text">hflush()</code>가 return하는 것은 디스크에 성공적으로 block들을 write한 경우가 아니라 <code class="language-text">datanode</code>의 메모리에 정상적으로 write된 것을 나타낸다. 따라서 disk에 저장하기 전에 전원이 꺼진다던지 등의 문제가 생기면 dataloss가 발생한다. 조금 더 확실하게 write를 보장하기 위해 <code class="language-text">hsync()</code>라는 method를 사용할 수 있다. disk와 sync하는 것을 뜻한다. </p>
<p><code class="language-text">hflush()</code>나 <code class="language-text">hsync()</code>를 통해 write를 guarantee하지 않으면, data loss가 발생할 수 있다. 따라서 적당한 시점에(?) 호출해줘야한다</p>
<h3 id="parallel-copying-with-distcp" style="position:relative;"><a href="#parallel-copying-with-distcp" aria-label="parallel copying with distcp permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Parallel Copying with distcp</h3>
<p>지금까지 소개한 HDFS 패턴은 모두 single-thread이다. <code class="language-text">distcp</code>를 사용하면 파일을 병렬적으로 처리할 수 있다. </p>
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">hadoop distcp file1 file2
hadoop distcp dir1 dir2</code></pre></div>
<p><code class="language-text">distcp</code>의 장점은, dir2가 존재하지 않는다면, dir2를 새로 생성하고 그 내부에 dir1의 내용을 복사한다는 것이다. dir2가 이미 있다면, 그 안에 dir1의 내용을 append할 수도 있고(dir2/dir1), <code class="language-text">-overwrite</code> option을 사용하면 dir1의 내용을 사용해서 dir2를 덮어쓸 수도 있다.</p>
<p><code class="language-text">distcp</code>는 <code class="language-text">MapReduce</code>로 구현되었다. 따라서 복사는 MapReduce의 map job으로 이루어져서 클러스터 내에서 병렬로 구동된다. reduce는 일어나지 않고(데이터 변형이 필요 없으니 그런 것 같음) <code class="language-text">distcp</code>는 각각의 <code class="language-text">mapper</code>에 동일한 양의 데이터를 주려고 한다. 최대 20개의 mapper가 사용되는데 설정하면 더 사용할 수도 있다. </p>
<p>일반적으로 hdfs 클러스터 간 데이터를 옮기기 위해 주로 사용한다. </p>
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">hadoop distcp -update -delete -p hdfs://namenode1/foo hdfs://namenode2/foo</code></pre></div>
<p><code class="language-text">-delete</code> 옵션을 사용하면 destination에서 해당 위치에 이미 존재하는 것들을 모두 삭제하고 덮어쓰는 것을 뜻한다.
<code class="language-text">-p</code> 옵션은 permissoin, block size, replication등의 파일 정보를 변경하지 않고 그대로 전달하는 것을 뜻한다.
만약 data를 전송하려는 두 hdfs 클러스터가 다른 버전의 hdfs를 사용한다면 <code class="language-text">webhdfs</code>를 사용하면 된다. </p>
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">hadoop distcp -update -delete -p webhdfs://namenode1/foo webhdfs://namenode2/foo</code></pre></div>
<h3 id="balancing-hdfs-cluster" style="position:relative;"><a href="#balancing-hdfs-cluster" aria-label="balancing hdfs cluster permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Balancing HDFS Cluster</h3>
<p>복사를 맘대로 하면 cluster내에 하나의 rack에 데이터가 엄청 모인다거나 하는 불상사가 발생할 수 있다. HDFS는 데이터가 균일하게 분산되어야 잘 작동하기 때문에, 이걸 주의해야한다. </p></div></div></div><div class="Post-module--post__footer--3WzWU"><div><p class="Meta-module--meta__date--29eD7">Published <!-- -->3 Oct 2022</p></div><div class="Tags-module--tags--1L_ct"><ul class="Tags-module--tags__list--91FqN"><li class="Tags-module--tags__list-item--1M30P"><a class="Tags-module--tags__list-item-link--3SL_8" href="/tag/hadoop/">Hadoop</a></li></ul></div><div class="Author-module--author--2Yefr"><p>I believe software engineers can change the world</p></div></div><div class="Post-module--post__comments--25y6I"><div class="comments-wrapper"><div>Loading script...</div><div></div></div></div></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/hadoop/how-hdfs-handles-data";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-f8d6bc3f3d1ba44ac510.js"],"app":["/app-98c54d1f8cdf11c156bf.js"],"component---node-modules-gatsby-plugin-offline-app-shell-js":["/component---node-modules-gatsby-plugin-offline-app-shell-js-2296adb1de2fc003fbd5.js"],"component---src-templates-categories-list-template-js":["/component---src-templates-categories-list-template-js-2181ec47d28e5c35d3e9.js"],"component---src-templates-category-template-js":["/component---src-templates-category-template-js-1d8a7e8fd18ba3deb560.js"],"component---src-templates-index-template-js":["/component---src-templates-index-template-js-a6471d1c35079e44b0ab.js"],"component---src-templates-not-found-template-js":["/component---src-templates-not-found-template-js-f76614cf3686e4001586.js"],"component---src-templates-page-template-js":["/component---src-templates-page-template-js-202f0ad010fd5725eedd.js"],"component---src-templates-post-template-js":["/component---src-templates-post-template-js-4c210b7b181b96af8152.js"],"component---src-templates-tag-template-js":["/component---src-templates-tag-template-js-b306378d336b55915358.js"],"component---src-templates-tags-list-template-js":["/component---src-templates-tags-list-template-js-2d7007993fc2bf0f9caf.js"]};/*]]>*/</script><script src="/polyfill-f8d6bc3f3d1ba44ac510.js" nomodule=""></script><script src="/component---src-templates-post-template-js-4c210b7b181b96af8152.js" async=""></script><script src="/643651a62fb35a9bb4f20061cb1f214a352d7976-bf398de8213e62a944ee.js" async=""></script><script src="/cd95ea5cbd2c605f26db819f07999610c9ff4310-e4f6eaaafd6673382cfa.js" async=""></script><script src="/styles-407fe62976dc5310c43e.js" async=""></script><script src="/app-98c54d1f8cdf11c156bf.js" async=""></script><script src="/532a2f07-e3aef1b806c2b9676cfd.js" async=""></script><script src="/framework-b049b847da93b37c0f49.js" async=""></script><script src="/webpack-runtime-2040cdfedb5607971d09.js" async=""></script></body></html>